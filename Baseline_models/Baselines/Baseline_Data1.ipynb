{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLxA0bczhlvs"
      },
      "source": [
        "# Baseline ML models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0-UKGwnzIMU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSidcUZch1yy"
      },
      "source": [
        "# Reading datasets and creating test train split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqLMpGP_5hX7",
        "outputId": "c54cd406-ace0-4ec8-f26b-784f4224fa7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = pd.read_csv('dataset.csv',sep=',',names=['Msg','Tag'])\n",
        "data1 = pd.read_csv('dataset_POS.csv',sep=',',names=['Msg','Tag'])\n",
        "data2 = pd.read_csv('dataset_stemmed.csv',sep=',',names=['Msg','Tag'])\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Msg</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The thing disgusting White woman groid White w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Americans acting like know talking</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Also intrested check webpage info european ame...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I think need take stand homes across country a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I think connection homosexuality Christianity ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Msg  Tag\n",
              "0  The thing disgusting White woman groid White w...    1\n",
              "1                Americans acting like know talking     0\n",
              "2  Also intrested check webpage info european ame...    0\n",
              "3  I think need take stand homes across country a...    0\n",
              "4  I think connection homosexuality Christianity ...    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl1WZY_L5jIS",
        "outputId": "5d049739-cd2c-4147-b931-a544485b16f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "data_x=data[\"Msg\"]\n",
        "data_y=data[\"Tag\"]\n",
        "cv = CountVectorizer()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=4)\n",
        "\n",
        "data1_x=data1[\"Msg\"]\n",
        "data1_y=data1[\"Tag\"]\n",
        "cv = CountVectorizer()\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(data1_x, data1_y, test_size=0.2, random_state=4)\n",
        "\n",
        "data2_x=data2[\"Msg\"]\n",
        "data2_y=data2[\"Tag\"]\n",
        "cv = CountVectorizer()\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(data2_x, data2_y, test_size=0.2, random_state=4)\n",
        "\n",
        "x_train.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8752    Also stupid white women watch Oprah realize fa...\n",
              "9141                     Jews insane literal demonic DNA \n",
              "5426                           I go I post soon possible \n",
              "2197    Hey live smithfield lived newport news jeffers...\n",
              "8687    Manic street preachers also red scum basically...\n",
              "Name: Msg, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm_-azEfNBUw",
        "outputId": "af470d1c-55a1-4816-cc1b-e4a0bd7d268c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "cv = CountVectorizer()\n",
        "x_traincv = cv.fit_transform([\"bayhdb hab ujhanvuz sniugnv\",\"shnf nfuje test test\",\"test anhf janbd whbj\"])\n",
        "x_traincv.toarray()\n",
        "cv.get_feature_names()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anhf',\n",
              " 'bayhdb',\n",
              " 'hab',\n",
              " 'janbd',\n",
              " 'nfuje',\n",
              " 'shnf',\n",
              " 'sniugnv',\n",
              " 'test',\n",
              " 'ujhanvuz',\n",
              " 'whbj']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMDwzdUKh88I"
      },
      "source": [
        "# Defining and fitting count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhYCjcAt5jmN",
        "outputId": "a2b0e3c9-e884-4b94-fe00-2df6794ef529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv1 = CountVectorizer()\n",
        "x_traincv=cv1.fit_transform(x_train.values.astype('U'))\n",
        "a=x_traincv.toarray()\n",
        "a[0]\n",
        "\n",
        "cv11 = CountVectorizer()\n",
        "x1_traincv=cv11.fit_transform(x1_train.values.astype('U'))\n",
        "a1=x1_traincv.toarray()\n",
        "a1[0]\n",
        "\n",
        "cv12 = CountVectorizer()\n",
        "x2_traincv=cv12.fit_transform(x2_train.values.astype('U'))\n",
        "a2=x2_traincv.toarray()\n",
        "a2[0]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwiYdh5J5kAQ",
        "outputId": "6d83e19b-5bc0-4ca7-87fa-c286ec3efef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "x_testcv=cv1.transform(x_test.values.astype('U'))\n",
        "x_testcv.toarray()\n",
        "\n",
        "x1_testcv=cv11.transform(x1_test.values.astype('U'))\n",
        "x1_testcv.toarray()\n",
        "\n",
        "x2_testcv=cv12.transform(x2_test.values.astype('U'))\n",
        "x2_testcv.toarray()\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR2ZyJO_iDa8"
      },
      "source": [
        "# 1) Naive Bayes classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq3uVoxn5kit",
        "outputId": "47867cee-0b0d-4095-bf3e-4fbf04bf6268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb1 = MultinomialNB()\n",
        "mnb2 = MultinomialNB()\n",
        "\n",
        "y_train=y_train.astype('int')\n",
        "y_train\n",
        "\n",
        "y1_train=y1_train.astype('int')\n",
        "y1_train\n",
        "\n",
        "y2_train=y2_train.astype('int')\n",
        "y2_train"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8752     0\n",
              "9141     1\n",
              "5426     0\n",
              "2197     0\n",
              "8687     1\n",
              "        ..\n",
              "6017     0\n",
              "709      0\n",
              "10679    0\n",
              "8366     0\n",
              "1146     0\n",
              "Name: Tag, Length: 8755, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjxv_OJy5lCx",
        "outputId": "01013bf1-97d3-40ae-997f-b4bd38872d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mnb.fit(x_traincv,y_train)\n",
        "mnb1.fit(x1_traincv,y1_train)\n",
        "mnb2.fit(x2_traincv,y2_train)\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybdRpLX05lcx",
        "outputId": "70a7ad78-5516-4c25-d253-e93b9eb67b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predictions=mnb.predict(x_testcv)\n",
        "print(predictions)\n",
        "a=np.array(y_test)\n",
        "\n",
        "predictions1=mnb1.predict(x1_testcv)\n",
        "print(predictions1)\n",
        "a1=np.array(y1_test)\n",
        "\n",
        "predictions2=mnb2.predict(x2_testcv)\n",
        "print(predictions2)\n",
        "a2=np.array(y2_test)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf33yL2hiKp4"
      },
      "source": [
        "# Calculating accuracies of the Naive Bayes model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tISrKgFYPAb4"
      },
      "source": [
        "count = 0\n",
        "for i in range (len(predictions)):\n",
        "    if predictions[i]==a[i]:\n",
        "        count=count+1\n",
        "\n",
        "count1 = 0\n",
        "for i in range (len(predictions1)):\n",
        "    if predictions1[i]==a1[i]:\n",
        "        count1=count1+1\n",
        "\n",
        "count2 = 0\n",
        "for i in range (len(predictions2)):\n",
        "    if predictions2[i]==a2[i]:\n",
        "        count2=count2+1"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH9L1zcjPLmg",
        "outputId": "1b22e207-9643-441f-c590-aa511ac34806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(\"Accuracy of Naive bayes with dataset\")\n",
        "print(count/len(predictions))\n",
        "print(\"Accuracy of Naive bayes with POS tagged dataset\")\n",
        "print(count1/len(predictions1))\n",
        "print(\"Accuracy of Naive bayes with stemmed and POS tagged dataset\")\n",
        "print(count2/len(predictions2))\n",
        "print(\" \")\n",
        "print(\"F1 score of Naive bayes with dataset\")\n",
        "print(f1_score(a, predictions, average='macro'))\n",
        "print(\"F1 score of Naive bayes with POS tagged dataset\")\n",
        "print(f1_score(a1, predictions1, average='macro'))\n",
        "print(\"F1 score of Naive bayes with stemmed and POS tagged dataset\")\n",
        "print(f1_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Precision score of Naive bayes with dataset\")\n",
        "print(precision_score(a, predictions, average='macro'))\n",
        "print(\"Precision score of Naive bayes with POS tagged dataset\")\n",
        "print(precision_score(a1, predictions1, average='macro'))\n",
        "print(\"Pricision score of Naive bayes with stemmed and POS tagged dataset\")\n",
        "print(precision_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Recall score of Naive bayes with dataset\")\n",
        "print(recall_score(a, predictions, average='macro'))\n",
        "print(\"Recall score of Naive bayes with POS tagged dataset\")\n",
        "print(recall_score(a1, predictions1, average='macro'))\n",
        "print(\"Recall score of Naive bayes with stemmed and POS tagged dataset\")\n",
        "print(recall_score(a2, predictions2, average='macro'))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Naive bayes with dataset\n",
            "0.8780264961169484\n",
            "Accuracy of Naive bayes with POS tagged dataset\n",
            "0.8793969849246231\n",
            "Accuracy of Naive bayes with stemmed and POS tagged dataset\n",
            "0.8784833257195066\n",
            " \n",
            "F1 score of Naive bayes with dataset\n",
            "0.5777016701529257\n",
            "F1 score of Naive bayes with POS tagged dataset\n",
            "0.5673913043478261\n",
            "F1 score of Naive bayes with stemmed and POS tagged dataset\n",
            "0.5566990687447849\n",
            " \n",
            "Precision score of Naive bayes with dataset\n",
            "0.7493289048637335\n",
            "Precision score of Naive bayes with POS tagged dataset\n",
            "0.7787907686439062\n",
            "Pricision score of Naive bayes with stemmed and POS tagged dataset\n",
            "0.7784954160254882\n",
            " \n",
            "Recall score of Naive bayes with dataset\n",
            "0.5613263501868887\n",
            "Recall score of Naive bayes with POS tagged dataset\n",
            "0.554525989092564\n",
            "Recall score of Naive bayes with stemmed and POS tagged dataset\n",
            "0.5479326603848191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmHhLNR0ZYUX"
      },
      "source": [
        "# 2) SVM classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoWAQe6xZhcY",
        "outputId": "9d54128d-b37e-4f58-b92b-40aa4bc36bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "svm = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
        "svm1 = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
        "svm2 = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
        "\n",
        "svm.fit(x_traincv,y_train)\n",
        "svm1.fit(x1_traincv,y1_train)\n",
        "svm2.fit(x2_traincv,y2_train)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_9Q7cTMatJw",
        "outputId": "4fcfadc5-4352-4bc9-ac90-caed2e6cd48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predictions=svm.predict(x_testcv)\n",
        "print(predictions)\n",
        "a=np.array(y_test)\n",
        "\n",
        "predictions1=svm1.predict(x1_testcv)\n",
        "print(predictions1)\n",
        "a1=np.array(y1_test)\n",
        "\n",
        "predictions2=svm2.predict(x2_testcv)\n",
        "print(predictions2)\n",
        "a2=np.array(y2_test)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcvW4XWfa3OC"
      },
      "source": [
        "count = 0\n",
        "for i in range (len(predictions)):\n",
        "    if predictions[i]==a[i]:\n",
        "        count=count+1\n",
        "\n",
        "count1 = 0\n",
        "for i in range (len(predictions1)):\n",
        "    if predictions1[i]==a1[i]:\n",
        "        count1=count1+1\n",
        "\n",
        "count2 = 0\n",
        "for i in range (len(predictions2)):\n",
        "    if predictions2[i]==a2[i]:\n",
        "        count2=count2+1"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXasoOjqa5QJ",
        "outputId": "da3b5d83-224d-467e-989c-0bdc222ba95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(\"Accuracy of SVM with dataset\")\n",
        "print(count/len(predictions))\n",
        "print(\"Accuracy of SVM with POS tagged dataset\")\n",
        "print(count1/len(predictions1))\n",
        "print(\"Accuracy of SVM with stemmed and POS tagged dataset\")\n",
        "print(count2/len(predictions2))\n",
        "print(\" \")\n",
        "print(\"Accuracy of SVM with dataset\")\n",
        "print(f1_score(a, predictions, average='macro'))\n",
        "print(\"Accuracy of SVM with POS tagged dataset\")\n",
        "print(f1_score(a1, predictions1, average='macro'))\n",
        "print(\"Accuracy of SVM with stemmed and POS tagged dataset\")\n",
        "print(f1_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Precision score of SVM with dataset\")\n",
        "print(precision_score(a, predictions, average='macro'))\n",
        "print(\"Precision score of SVM with POS tagged dataset\")\n",
        "print(precision_score(a1, predictions1, average='macro'))\n",
        "print(\"Pricision score of SVM with stemmed and POS tagged dataset\")\n",
        "print(precision_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Recall score of SVM with dataset\")\n",
        "print(recall_score(a, predictions, average='macro'))\n",
        "print(\"Recall score of SVM with POS tagged dataset\")\n",
        "print(recall_score(a1, predictions1, average='macro'))\n",
        "print(\"Recall score of SVM with stemmed and POS tagged dataset\")\n",
        "print(recall_score(a2, predictions2, average='macro'))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVM with dataset\n",
            "0.8725445408862494\n",
            "Accuracy of SVM with POS tagged dataset\n",
            "0.8725445408862494\n",
            "Accuracy of SVM with stemmed and POS tagged dataset\n",
            "0.8725445408862494\n",
            " \n",
            "Accuracy of SVM with dataset\n",
            "0.47644373577481447\n",
            "Accuracy of SVM with POS tagged dataset\n",
            "0.4730012037432532\n",
            "Accuracy of SVM with stemmed and POS tagged dataset\n",
            "0.47644373577481447\n",
            " \n",
            "Precision score of SVM with dataset\n",
            "0.8113844393592677\n",
            "Precision score of SVM with POS tagged dataset\n",
            "0.9362139917695473\n",
            "Pricision score of SVM with stemmed and POS tagged dataset\n",
            "0.8113844393592677\n",
            " \n",
            "Recall score of SVM with dataset\n",
            "0.5050760237844775\n",
            "Recall score of SVM with POS tagged dataset\n",
            "0.50355871886121\n",
            "Recall score of SVM with stemmed and POS tagged dataset\n",
            "0.5050760237844775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7nJnITfbZEk"
      },
      "source": [
        "# 3) Logistic regression Classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg6bylYnbf1e",
        "outputId": "0ca0890a-19ac-4344-8517-fbf1b8261253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "lr = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
        "lr1 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
        "lr2 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
        "\n",
        "lr.fit(x_traincv,y_train)\n",
        "lr1.fit(x1_traincv,y1_train)\n",
        "lr2.fit(x2_traincv,y2_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYfJ_8Ihbgfm",
        "outputId": "812e7223-2256-4512-956f-cca109cb1e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predictions=lr.predict(x_testcv)\n",
        "print(predictions)\n",
        "a=np.array(y_test)\n",
        "\n",
        "predictions1=lr1.predict(x1_testcv)\n",
        "print(predictions1)\n",
        "a1=np.array(y1_test)\n",
        "\n",
        "predictions2=lr2.predict(x2_testcv)\n",
        "print(predictions2)\n",
        "a2=np.array(y2_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHkzWliLbgx_"
      },
      "source": [
        "count = 0\n",
        "for i in range (len(predictions)):\n",
        "    if predictions[i]==a[i]:\n",
        "        count=count+1\n",
        "\n",
        "count1 = 0\n",
        "for i in range (len(predictions1)):\n",
        "    if predictions1[i]==a1[i]:\n",
        "        count1=count1+1\n",
        "\n",
        "count2 = 0\n",
        "for i in range (len(predictions2)):\n",
        "    if predictions2[i]==a2[i]:\n",
        "        count2=count2+1"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPeV-ufMbhJ5",
        "outputId": "d03fa6f5-775c-4c4d-e2ec-08cc66dd0822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(\"Accuracy of LR with dataset\")\n",
        "print(count/len(predictions))\n",
        "print(\"Accuracy of LR with POS tagged dataset\")\n",
        "print(count1/len(predictions1))\n",
        "print(\"Accuracy of LR with stemmed and POS tagged dataset\")\n",
        "print(count2/len(predictions2))\n",
        "print(\" \")\n",
        "print(\"Accuracy of LR with dataset\")\n",
        "print(f1_score(a, predictions, average='macro'))\n",
        "print(\"Accuracy of LR with POS tagged dataset\")\n",
        "print(f1_score(a1, predictions1, average='macro'))\n",
        "print(\"Accuracy of LR with stemmed and POS tagged dataset\")\n",
        "print(f1_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Precision score of LR with dataset\")\n",
        "print(precision_score(a, predictions, average='macro'))\n",
        "print(\"Precision score of LR with POS tagged dataset\")\n",
        "print(precision_score(a1, predictions1, average='macro'))\n",
        "print(\"Pricision score of LR with stemmed and POS tagged dataset\")\n",
        "print(precision_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Recall score of LR with dataset\")\n",
        "print(recall_score(a, predictions, average='macro'))\n",
        "print(\"Recall score of LR with POS tagged dataset\")\n",
        "print(recall_score(a1, predictions1, average='macro'))\n",
        "print(\"Recall score of LR with stemmed and POS tagged dataset\")\n",
        "print(recall_score(a2, predictions2, average='macro'))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of LR with dataset\n",
            "0.8766560073092736\n",
            "Accuracy of LR with POS tagged dataset\n",
            "0.8734582000913659\n",
            "Accuracy of LR with stemmed and POS tagged dataset\n",
            "0.8743718592964824\n",
            " \n",
            "Accuracy of LR with dataset\n",
            "0.6367095298977183\n",
            "Accuracy of LR with POS tagged dataset\n",
            "0.5960676159547006\n",
            "Accuracy of LR with stemmed and POS tagged dataset\n",
            "0.6191133324095499\n",
            " \n",
            "Precision score of LR with dataset\n",
            "0.7201042372243547\n",
            "Precision score of LR with POS tagged dataset\n",
            "0.7052683694713857\n",
            "Pricision score of LR with stemmed and POS tagged dataset\n",
            "0.7098678410432989\n",
            " \n",
            "Recall score of LR with dataset\n",
            "0.6090939442094347\n",
            "Recall score of LR with POS tagged dataset\n",
            "0.5753961592694554\n",
            "Recall score of LR with stemmed and POS tagged dataset\n",
            "0.59412792736334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZiSGxQqbj0X"
      },
      "source": [
        "# 4) Decision Trees Classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp6Ey3WobhdZ",
        "outputId": "7d9548f5-6b5d-4b54-bed0-0d4c0aac87c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "dt = tree.DecisionTreeClassifier()\n",
        "dt1 = tree.DecisionTreeClassifier()\n",
        "dt2 = tree.DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(x_traincv,y_train)\n",
        "dt1.fit(x1_traincv,y1_train)\n",
        "dt2.fit(x2_traincv,y2_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YzejPoJbuZD",
        "outputId": "37c471b8-1497-4e9b-ed05-972aae939ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "predictions=dt.predict(x_testcv)\n",
        "print(predictions)\n",
        "a=np.array(y_test)\n",
        "\n",
        "predictions1=dt1.predict(x1_testcv)\n",
        "print(predictions1)\n",
        "a1=np.array(y1_test)\n",
        "\n",
        "predictions2=dt2.predict(x2_testcv)\n",
        "print(predictions2)\n",
        "a2=np.array(y2_test)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-98tfH4buug"
      },
      "source": [
        "count = 0\n",
        "for i in range (len(predictions)):\n",
        "    if predictions[i]==a[i]:\n",
        "        count=count+1\n",
        "\n",
        "count1 = 0\n",
        "for i in range (len(predictions1)):\n",
        "    if predictions1[i]==a1[i]:\n",
        "        count1=count1+1\n",
        "\n",
        "count2 = 0\n",
        "for i in range (len(predictions2)):\n",
        "    if predictions2[i]==a2[i]:\n",
        "        count2=count2+1"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvJ4yhPhbvCM",
        "outputId": "3263403d-dead-4b8f-a101-a4fb1c5edce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(\"Accuracy of decision trees with dataset\")\n",
        "print(count/len(predictions))\n",
        "print(\"Accuracy of decision trees with POS tagged dataset\")\n",
        "print(count1/len(predictions1))\n",
        "print(\"Accuracy of decision trees with stemmed and POS tagged dataset\")\n",
        "print(count2/len(predictions2))\n",
        "print(\" \")\n",
        "print(\"Accuracy of decision trees with dataset\")\n",
        "print(f1_score(a, predictions, average='macro'))\n",
        "print(\"Accuracy of decision trees with POS tagged dataset\")\n",
        "print(f1_score(a1, predictions1, average='macro'))\n",
        "print(\"Accuracy of decision trees with stemmed and POS tagged dataset\")\n",
        "print(f1_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Precision score of decision trees with dataset\")\n",
        "print(precision_score(a, predictions, average='macro'))\n",
        "print(\"Precision score of decision trees with POS tagged dataset\")\n",
        "print(precision_score(a1, predictions1, average='macro'))\n",
        "print(\"Pricision score of decision trees with stemmed and POS tagged dataset\")\n",
        "print(precision_score(a2, predictions2, average='macro'))\n",
        "print(\" \")\n",
        "print(\"Recall score of decision trees with dataset\")\n",
        "print(recall_score(a, predictions, average='macro'))\n",
        "print(\"Recall score of decision trees with POS tagged dataset\")\n",
        "print(recall_score(a1, predictions1, average='macro'))\n",
        "print(\"Recall score of decision trees with stemmed and POS tagged dataset\")\n",
        "print(recall_score(a2, predictions2, average='macro'))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of decision trees with dataset\n",
            "0.8579259936043856\n",
            "Accuracy of decision trees with POS tagged dataset\n",
            "0.8579259936043856\n",
            "Accuracy of decision trees with stemmed and POS tagged dataset\n",
            "0.8542713567839196\n",
            " \n",
            "Accuracy of decision trees with dataset\n",
            "0.6394379549866136\n",
            "Accuracy of decision trees with POS tagged dataset\n",
            "0.596474256954484\n",
            "Accuracy of decision trees with stemmed and POS tagged dataset\n",
            "0.6247314965737432\n",
            " \n",
            "Precision score of decision trees with dataset\n",
            "0.6643687953770929\n",
            "Precision score of decision trees with POS tagged dataset\n",
            "0.6440535339515485\n",
            "Pricision score of decision trees with stemmed and POS tagged dataset\n",
            "0.6508532414471057\n",
            " \n",
            "Recall score of decision trees with dataset\n",
            "0.6241438931041429\n",
            "Recall score of decision trees with POS tagged dataset\n",
            "0.5801420503293866\n",
            "Recall score of decision trees with stemmed and POS tagged dataset\n",
            "0.6099090176593029\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}